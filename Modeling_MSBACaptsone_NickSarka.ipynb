{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59a3082e",
   "metadata": {},
   "source": [
    "### Loading in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a615600",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, roc_auc_score, roc_curve,confusion_matrix, classification_report \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import statsmodels.api as sm\n",
    "import catboost as cb\n",
    "from catboost import CatBoostRegressor  \n",
    "from catboost import CatBoostClassifier \n",
    "# Warnings Management\n",
    "import warnings  # To suppress warnings which can clutter the notebook\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55017a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"application_train.csv\")\n",
    "test_df = pd.read_csv(\"application_test.csv\")\n",
    "previous_application = pd.read_csv(\"previous_application.csv\")\n",
    "POS_CASH_balance = pd.read_csv(\"POS_CASH_balance.csv\")\n",
    "bureau = pd.read_csv(\"bureau.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48118c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority Class Performance Benchmark: 91.92711805431351%\n"
     ]
    }
   ],
   "source": [
    "class_counts = train_df['TARGET'].value_counts()\n",
    "# Determine the majority class and its proportion in the dataset\n",
    "majority_class_proportion = class_counts.max() / train_df.shape[0] * 100\n",
    "print(f\"Majority Class Performance Benchmark: {majority_class_proportion}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "566ff160",
   "metadata": {},
   "outputs": [],
   "source": [
    "values =train_df.isna().sum() / len(train_df)## Checking for the percent of missing values in each column\n",
    "values.sort_values(ascending=False)\n",
    "def drop_columns(df, threshold=.5,exempt_columns=['TARGET']): ## Seting threshold \n",
    "    missing = df.isna().sum() / len(df)\n",
    "    columns_to_drop = missing[(values > threshold)].index.tolist()\n",
    "#     existing = [col for col in columns_to_drop if col in df.columns]\n",
    "    df_cleaned = df.drop(columns=columns_to_drop)\n",
    "    return df_cleaned  \n",
    "train_df = drop_columns(train_df) \n",
    "test_df = drop_columns(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6d80978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute(df):\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == 'O': \n",
    "            mode_value = df[column].mode().iloc[0]\n",
    "            df[column] = df[column].fillna(mode_value)  ## Impute the mode value for object columns\n",
    "        else:\n",
    "            median_value = df[column].median()\n",
    "            df[column] = df[column].fillna(median_value) ## Impute the median value for int or num columns\n",
    "    return df\n",
    "train_df = impute(train_df)\n",
    "test_df = impute(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9aea123e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merging the application data\n",
    "prev_app_agg = previous_application.groupby('SK_ID_CURR').agg({'AMT_APPLICATION': ['mean'],\n",
    "                                                               'AMT_CREDIT': ['mean'],\n",
    "                                                               'DAYS_DECISION': ['mean'],\n",
    "                                                               'CNT_PAYMENT': ['mean']})\n",
    "prev_app_agg.columns = ['PREVAPP_' + ('_'.join(col).upper()) for col in prev_app_agg.columns.values]\n",
    "\n",
    "application_train = train_df.merge(prev_app_agg, on='SK_ID_CURR', how='left')\n",
    "application_test = test_df.merge(prev_app_agg, on='SK_ID_CURR', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a1ce169",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merging Cash \n",
    "POS_CASH_agg = POS_CASH_balance.groupby('SK_ID_CURR').agg({'MONTHS_BALANCE': ['max'],\n",
    "                                                           'CNT_INSTALMENT': ['mean'],\n",
    "                                                           'SK_DPD': ['max']})\n",
    "POS_CASH_agg.columns = ['POSCASH_' + ('_'.join(col).upper()) for col in POS_CASH_agg.columns.values]\n",
    "\n",
    "application_train = application_train.merge(POS_CASH_agg, on='SK_ID_CURR', how='left')\n",
    "application_test = application_test.merge(POS_CASH_agg, on='SK_ID_CURR', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a508f54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau_agg = bureau.groupby('SK_ID_CURR').agg({'DAYS_CREDIT': ['mean', 'min', 'max'],\n",
    "                                               'CREDIT_DAY_OVERDUE': ['max'],\n",
    "                                               'DAYS_CREDIT_ENDDATE': ['mean'],\n",
    "                                               'DAYS_CREDIT_UPDATE': ['mean']})\n",
    "# Flattening the multi-level columns\n",
    "bureau_agg.columns = ['BUREAU_' + ('_'.join(col).upper()) for col in bureau_agg.columns.values]\n",
    "\n",
    "# Merging aggregated bureau data with main application data\n",
    "application_train = application_train.merge(bureau_agg, on='SK_ID_CURR', how='left')\n",
    "application_test = application_test.merge(bureau_agg, on='SK_ID_CURR', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bbe696b",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train = impute(application_train)\n",
    "app_test = impute(application_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6af50e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding Division and Subtraction Based Features\n",
    "application_train['NEW_EXT_SOURCE_3_DIVIDE'] = application_train['EXT_SOURCE_3'] / (application_train['AMT_CREDIT'] + 0.01) # Avoid division by zero\n",
    "application_test['NEW_EXT_SOURCE_3_DIVIDE'] = application_test['EXT_SOURCE_3'] / (application_test['AMT_CREDIT'] + 0.01)\n",
    "## Adding in Yearly Interest Rate Calculations \n",
    "app_train['YEARLY_INTEREST_RATE'] = (app_train['AMT_ANNUITY'] * 12) / app_train['AMT_CREDIT']\n",
    "app_test['YEARLY_INTEREST_RATE'] = (app_test['AMT_ANNUITY'] * 12) / app_test['AMT_CREDIT']\n",
    "## Adding in Ratio's\n",
    "app_train['INCOME_TO_ANNUITY_RATIO'] = app_train['AMT_INCOME_TOTAL'] / app_train['AMT_ANNUITY']\n",
    "app_train['INCOME_TO_CREDIT_RATIO'] = app_train['AMT_INCOME_TOTAL'] / app_train['AMT_CREDIT']\n",
    "\n",
    "app_test['INCOME_TO_ANNUITY_RATIO'] = app_test['AMT_INCOME_TOTAL'] / app_test['AMT_ANNUITY']\n",
    "app_test['INCOME_TO_CREDIT_RATIO'] = app_test['AMT_INCOME_TOTAL'] / app_test['AMT_CREDIT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "469e5092",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42) # initialize K fold\n",
    "X = app_train\n",
    "def get_categorical_features(df): ## Creating a function to handle categorical features and then pass them on to the cat features in CatBoost\n",
    "    cat_features = [col for col in df.columns if df[col].dtype == 'object' or df[col].dtype.name == 'category']\n",
    "    return cat_features\n",
    "cat_features = get_categorical_features(app_train)\n",
    "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')  # Creating an encoder object\n",
    "X_encoded = pd.DataFrame(encoder.fit_transform(X[cat_features]))  # Encoding categorical data\n",
    "X_encoded.columns = encoder.get_feature_names_out(cat_features)  # Naming the new columns\n",
    "\n",
    "# Drop original categorical columns and concatenate the new encoded columns\n",
    "X = X.drop(columns=cat_features)\n",
    "X = pd.concat([X, X_encoded], axis=1)\n",
    "# Select features and target; replace 'feature1', 'feature2', ..., 'target' with your actual column names\n",
    "y = X['TARGET']\n",
    "X['EXT_SOURCE_AVG'] = (X['EXT_SOURCE_2'] + X['EXT_SOURCE_3']) / 2\n",
    "X = X[['EXT_SOURCE_AVG', 'YEARLY_INTEREST_RATE', 'DAYS_BIRTH', \n",
    "       'AMT_GOODS_PRICE', 'PREVAPP_CNT_PAYMENT_MEAN',\n",
    "      'POSCASH_CNT_INSTALMENT_MEAN', 'DAYS_EMPLOYED']]\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1a587f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.258043\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                 TARGET   No. Observations:               215257\n",
      "Model:                          Logit   Df Residuals:                   215249\n",
      "Method:                           MLE   Df Model:                            7\n",
      "Date:                Wed, 01 May 2024   Pseudo R-squ.:                 0.08149\n",
      "Time:                        13:00:01   Log-Likelihood:                -55546.\n",
      "converged:                       True   LL-Null:                       -60473.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "===============================================================================================\n",
      "                                  coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------\n",
      "const                           0.4067      0.053      7.731      0.000       0.304       0.510\n",
      "EXT_SOURCE_AVG                 -5.0935      0.058    -87.748      0.000      -5.207      -4.980\n",
      "YEARLY_INTEREST_RATE           -0.0488      0.036     -1.337      0.181      -0.120       0.023\n",
      "DAYS_BIRTH                   3.175e-05   2.42e-06     13.123      0.000     2.7e-05    3.65e-05\n",
      "AMT_GOODS_PRICE             -2.038e-07   2.89e-08     -7.049      0.000   -2.61e-07   -1.47e-07\n",
      "PREVAPP_CNT_PAYMENT_MEAN        0.0093      0.001      6.946      0.000       0.007       0.012\n",
      "POSCASH_CNT_INSTALMENT_MEAN     0.0065      0.001      4.522      0.000       0.004       0.009\n",
      "DAYS_EMPLOYED               -5.962e-07   8.23e-08     -7.243      0.000   -7.58e-07   -4.35e-07\n",
      "===============================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train = sm.add_constant(X_train)\n",
    "# Fit logistic regression model using statsmodels\n",
    "logit_model = sm.Logit(y_train, X_train)\n",
    "result = logit_model.fit()\n",
    "print(result.summary())\n",
    "\n",
    "#logreg = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "#logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70826f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.6436110\tbest: 0.6436110 (0)\ttotal: 218ms\tremaining: 1m 48s\n",
      "200:\ttest: 0.7664620\tbest: 0.7664620 (200)\ttotal: 54.4s\tremaining: 1m 20s\n",
      "400:\ttest: 0.7693961\tbest: 0.7694594 (398)\ttotal: 1m 42s\tremaining: 25.4s\n",
      "499:\ttest: 0.7699555\tbest: 0.7699555 (499)\ttotal: 2m 6s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.769955465\n",
      "bestIteration = 499\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x154205ad0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42) # initialize K fold\n",
    "\n",
    "X = app_train\n",
    "y = X.pop('TARGET')\n",
    "\n",
    "cv_results = [] ## Set up empty data frame\n",
    "cv_auc_scores = []\n",
    "cv_accuracy_scores = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index] ## Create for loop for the folds\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "def get_categorical_features(df): ## Creating a function to handle categorical features and then pass them on to the cat features in CatBoost\n",
    "    cat_features = [col for col in df.columns if df[col].dtype == 'object' or df[col].dtype.name == 'category']\n",
    "    return cat_features \n",
    "\n",
    "cat_features = get_categorical_features(app_train)\n",
    "\n",
    "\n",
    "model = cb.CatBoostClassifier(\n",
    "    iterations=500,\n",
    "    learning_rate=0.1,\n",
    "    depth=6,\n",
    "    loss_function='Logloss',  \n",
    "    eval_metric='AUC',       \n",
    "    custom_metric=['AUC','Accuracy'],\n",
    "    random_seed=42,\n",
    "    verbose=200\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    cat_features=cat_features, \n",
    "    eval_set=(X_test, y_test) ## Run and test the model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47b0905",
   "metadata": {},
   "source": [
    "## Evaluate Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a80ce737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold AUC: 0.7699554649761445, Fold Accuracy: 0.9197424474000846\n",
      "Average AUC across folds: 0.7699554649761445\n",
      "Average Accuracy across folds: 0.9197424474000846\n"
     ]
    }
   ],
   "source": [
    "best_iteration = model.get_best_iteration()\n",
    "eval_results = model.get_evals_result()\n",
    "try:\n",
    "    # Try the expected key for a single validation set\n",
    "    auc = eval_results['validation']['AUC'][best_iteration]\n",
    "except KeyError:\n",
    "    # Log an error message and continue with a default value or alternative action\n",
    "    print(\"KeyError encountered. Adjust the key based on your eval_results structure.\")\n",
    "    auc = None  # You might choose to set a default value or take other actions\n",
    "    \n",
    "# Calculate accuracy only if auc could be retrieved\n",
    "if auc is not None:\n",
    "    accuracy = model.score(X_test, y_test)\n",
    "    # Append metrics to lists\n",
    "    cv_auc_scores.append(auc)\n",
    "    cv_accuracy_scores.append(accuracy)\n",
    "\n",
    "    \n",
    "    print(f\"Fold AUC: {auc}, Fold Accuracy: {accuracy}\")\n",
    "else:\n",
    "    # Handle the case where AUC couldn't be determined\n",
    "    print(\"AUC could not be determined for this fold due to KeyError.\")\n",
    "\n",
    "if cv_auc_scores and cv_accuracy_scores:  # Ensure the lists aren't empty\n",
    "    # Calculate and print the average AUC and accuracy across all folds\n",
    "    average_auc = np.mean(cv_auc_scores)\n",
    "    average_accuracy = np.mean(cv_accuracy_scores)\n",
    "    print(f\"Average AUC across folds: {average_auc}\")\n",
    "    print(f\"Average Accuracy across folds: {average_accuracy}\")\n",
    "else:\n",
    "    print(\"No AUC or accuracy scores were collected.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
